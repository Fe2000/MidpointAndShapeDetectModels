{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['x', 'y','steering','throttle','image'])\n",
    "directory = 'images_labeled/'\n",
    "\n",
    "images = list()\n",
    "for f in os.listdir(directory):\n",
    "    if os.path.isfile(directory+f):\n",
    "        entry = f.split(\",\")\n",
    "        for i in range(len(entry)-1):\n",
    "            entry[i] = np.float32(entry[i])\n",
    "            if i == 0 or i == 1:\n",
    "                entry[i] = entry[i]/224\n",
    "        entry[4] = directory+f\n",
    "        df.loc[len(df.index)] = entry\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipline\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# array of image files to read in parse_image\n",
    "files = df[\"image\"].tolist()\n",
    "\n",
    "files = tf.constant(files)\n",
    "# bounding_box = tf.constant(df[[\"x\", \"y\"]].values.tolist())\n",
    "steering = tf.constant(df[\"steering\"].tolist())\n",
    "\n",
    "# dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((files,steering))\n",
    "\n",
    "dataset = dataset.shuffle(300)\n",
    "ds_train = dataset.take(int(len(dataset)*.8)) # take first 80%\n",
    "ds_validation = dataset.skip(int(len(dataset)*.8)).take(int(len(dataset)*.1)) # skip first 80%, take next 10%\n",
    "ds_test = dataset.skip(int(len(dataset)*.9)) # skip first 90%, take rest\n",
    "\n",
    "# image manipulation\n",
    "# already normalizes pixel values\n",
    "def parse_image(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.io.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "# optimize pipeline\n",
    "ds_train = ds_train.map(parse_image)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(parse_image)\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "ds_validation = ds_validation.map(parse_image)\n",
    "ds_validation = ds_validation.batch(BATCH_SIZE)\n",
    "ds_validation = ds_validation.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# batch iterator\n",
    "iterator_train = iter(ds_train)\n",
    "images_train, labels_train = iterator_train.get_next()\n",
    "iterator_test = iter(ds_test)\n",
    "images_test, labels_test = iterator_test.get_next()\n",
    "iterator_validation = iter(ds_validation)\n",
    "images_validation, labels_validation = iterator_validation.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 244, 244, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 48,786,306\n",
      "Trainable params: 48,724,994\n",
      "Non-trainable params: 61,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet50\n",
    "res_input = layers.Input(shape=(244,244,3))\n",
    "resnet50 = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling='max', classes=1000\n",
    ")(res_input)\n",
    "resnet50 = layers.Flatten()(resnet50)\n",
    "resnet50 = layers.Dense(4096, activation='relu')(resnet50)\n",
    "resnet50 = layers.Dense(4096, activation='relu')(resnet50)\n",
    "resnet50 = layers.BatchNormalization()(resnet50)\n",
    "resnet50 = layers.Dense(2, activation='tanh')(resnet50)\n",
    "\n",
    "resnet50 = keras.Model(res_input, resnet50)\n",
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(224, 224, 3))\n",
    "model = layers.Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
    "model = layers.MaxPooling2D((2,2), padding='same')(model)\n",
    "model = layers.Conv2D(96, (3,3), activation='relu', padding='same')(model)\n",
    "model = layers.MaxPooling2D((2,2), padding='same')(model)\n",
    "model = layers.Conv2D(128, (3,3), activation='relu', padding='same')(model)\n",
    "model = layers.MaxPooling2D((2,2), padding='same')(model)\n",
    "model = layers.Conv2D(512, (3,3), activation='relu', padding='same')(model)\n",
    "model = layers.MaxPooling2D((2,2), padding='same')(model)\n",
    "model = layers.Flatten()(model)\n",
    "\n",
    "model = layers.Dense(256, activation='relu')(model)\n",
    "model = layers.Dense(128, activation='relu')(model)\n",
    "model = layers.Dense(64, activation='relu')(model)\n",
    "model = layers.Dense(2, activation='tanh')(model)\n",
    "model = keras.Model(input_layer, model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='MSE', metrics=[\"accuracy\"])\n",
    "model.fit(ds_train, epochs=100, validation_data=ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "56/56 [==============================] - 46s 731ms/step - loss: 0.7817 - accuracy: 0.0958 - val_loss: 1.8224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 40s 710ms/step - loss: 0.4546 - accuracy: 0.1922 - val_loss: 1.4068 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "54/56 [===========================>..] - ETA: 1s - loss: 0.3214 - accuracy: 0.2130"
     ]
    }
   ],
   "source": [
    "resnet50.compile(optimizer='adam', loss='MSE', metrics=['accuracy'])\n",
    "resnet50.fit(ds_train, epochs=1000, validation_data=ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"experiment_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7baa10a",
   "metadata": {},
   "source": [
    "# Fernando Estrada¶\n",
    "Problem Set 2: Convolutional Neural Networks CS 4143 - Deep Learning\n",
    "\n",
    "February 21, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce666aeb",
   "metadata": {},
   "source": [
    "# Libraries and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685c0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import Input\n",
    "from keras import Sequential\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np                      \n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import pyplot as plt    \n",
    "import cv2\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ee2a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums of GPus:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"nums of GPus: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3494f97",
   "metadata": {},
   "source": [
    "# Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661dced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036de4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path , nrows= 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d46d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Files</th>\n",
       "      <th>Label</th>\n",
       "      <th>Centers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/img0.jpg</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>(341, 265)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/img1.jpg</td>\n",
       "      <td>triangle</td>\n",
       "      <td>(383, 199)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/img2.jpg</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>(487, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/img3.jpg</td>\n",
       "      <td>triangle</td>\n",
       "      <td>(389, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/img4.jpg</td>\n",
       "      <td>triangle</td>\n",
       "      <td>(145, 221)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>images/img14995.jpg</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>(259, 227)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>images/img14996.jpg</td>\n",
       "      <td>triangle</td>\n",
       "      <td>(356, 268)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>images/img14997.jpg</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>(341, 272)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>images/img14998.jpg</td>\n",
       "      <td>triangle</td>\n",
       "      <td>(355, 107)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>images/img14999.jpg</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>(241, 166)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Files      Label     Centers\n",
       "0          images/img0.jpg  rectangle  (341, 265)\n",
       "1          images/img1.jpg   triangle  (383, 199)\n",
       "2          images/img2.jpg  rectangle  (487, 280)\n",
       "3          images/img3.jpg   triangle  (389, 257)\n",
       "4          images/img4.jpg   triangle  (145, 221)\n",
       "...                    ...        ...         ...\n",
       "14995  images/img14995.jpg  rectangle  (259, 227)\n",
       "14996  images/img14996.jpg   triangle  (356, 268)\n",
       "14997  images/img14997.jpg  rectangle  (341, 272)\n",
       "14998  images/img14998.jpg   triangle  (355, 107)\n",
       "14999  images/img14999.jpg  rectangle  (241, 166)\n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b2cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ np.asarray(ImageOps.grayscale(Image.open(x)), dtype = 'float32')/255  for x in data['Files'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bbbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.iloc[ : , 1:2 ]\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "Y = enc.fit_transform(Y).toarray()\n",
    "\n",
    "Y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155fa2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2\n",
       "0      0.0  1.0  0.0\n",
       "1      0.0  0.0  1.0\n",
       "2      0.0  1.0  0.0\n",
       "3      0.0  0.0  1.0\n",
       "4      0.0  0.0  1.0\n",
       "...    ...  ...  ...\n",
       "14995  0.0  1.0  0.0\n",
       "14996  0.0  0.0  1.0\n",
       "14997  0.0  1.0  0.0\n",
       "14998  0.0  0.0  1.0\n",
       "14999  0.0  1.0  0.0\n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c932a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.asarray(images)\n",
    "images = images.reshape(  len(images), 400, 600, 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84fa787",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(images,Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1459649",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b6bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 398, 598, 4)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 199, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 197, 297, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 98, 148, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 96, 146, 4)        148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 73, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 71, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 35, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 21, 33, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 16, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 14, 4)          148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 339       \n",
      "=================================================================\n",
      "Total params: 1,119\n",
      "Trainable params: 1,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Input(shape=(400,600 ,1), dtype=\"float32\"   )  )\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add( Dense(3, activation='sigmoid')  )\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2f7ec45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy' , 'Recall' , 'Precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107abd6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac4798c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "169/169 [==============================] - 18s 90ms/step - loss: 1.0820 - accuracy: 0.3746 - recall: 0.4792 - precision: 0.3762 - val_loss: 0.8907 - val_accuracy: 0.5783 - val_recall: 0.6442 - val_precision: 0.5569\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 14s 80ms/step - loss: 0.8740 - accuracy: 0.5903 - recall: 0.6189 - precision: 0.5748 - val_loss: 0.7128 - val_accuracy: 0.6767 - val_recall: 0.6900 - val_precision: 0.6645\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.6463 - accuracy: 0.7307 - recall: 0.7353 - precision: 0.6759 - val_loss: 0.4017 - val_accuracy: 0.8633 - val_recall: 0.8800 - val_precision: 0.7021\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.3214 - accuracy: 0.8972 - recall: 0.9109 - precision: 0.6975 - val_loss: 0.2591 - val_accuracy: 0.9208 - val_recall: 0.9408 - val_precision: 0.7065\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.2041 - accuracy: 0.9375 - recall: 0.9474 - precision: 0.7130 - val_loss: 0.2358 - val_accuracy: 0.9367 - val_recall: 0.9483 - val_precision: 0.6952\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 14s 80ms/step - loss: 0.1499 - accuracy: 0.9591 - recall: 0.9642 - precision: 0.6975 - val_loss: 0.2143 - val_accuracy: 0.9525 - val_recall: 0.9617 - val_precision: 0.6977\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.1134 - accuracy: 0.9661 - recall: 0.9737 - precision: 0.7065 - val_loss: 0.2173 - val_accuracy: 0.9642 - val_recall: 0.9767 - val_precision: 0.6743\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.0919 - accuracy: 0.9739 - recall: 0.9775 - precision: 0.7030 - val_loss: 0.2188 - val_accuracy: 0.9567 - val_recall: 0.9725 - val_precision: 0.6845\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.0983 - accuracy: 0.9658 - recall: 0.9781 - precision: 0.7052 - val_loss: 0.2658 - val_accuracy: 0.9667 - val_recall: 0.9667 - val_precision: 0.7077\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 14s 81ms/step - loss: 0.0909 - accuracy: 0.9647 - recall: 0.9741 - precision: 0.7037 - val_loss: 0.1913 - val_accuracy: 0.9642 - val_recall: 0.9850 - val_precision: 0.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d8d9afc70>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( x_train, y_train, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52871108",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d2eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('ShapeDetectMoreDataGpuV2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22d1ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 8s 18ms/step - loss: 0.0670 - accuracy: 0.9757 - recall: 0.9067 - precision: 0.8326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06701995432376862,\n",
       " 0.9756666421890259,\n",
       " 0.9066666960716248,\n",
       " 0.8325681090354919]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45d452d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ShapeDetectMoreDataGpuFilter\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ShapeDetectMoreDataGpuV2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a1a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheck = keras.models.load_model('ShapeDetectMoreDataGpuV2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e99b816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0573 - accuracy: 0.9793 - recall: 0.9073 - precision: 0.8422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05726794898509979,\n",
       " 0.9793333411216736,\n",
       " 0.9073333144187927,\n",
       " 0.8422029614448547]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelCheck.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "039e1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 398, 598, 4)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 199, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 197, 297, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 98, 148, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 96, 146, 4)        148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 48, 73, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 46, 71, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 23, 35, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 21, 33, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 10, 16, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 8, 14, 4)          148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 4, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 339       \n",
      "=================================================================\n",
      "Total params: 1,119\n",
      "Trainable params: 1,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelCheck.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f35fd5",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77218473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(arg1):\n",
    "    modelTest = keras.models.load_model('ShapeDetectMoreDataGpuV1')\n",
    "\n",
    "    image1 = np.asarray(ImageOps.grayscale(Image.open(arg1)), dtype = 'float32')/255\n",
    "    \n",
    "    image1 = np.asarray(image1)\n",
    "    image1 = image1.reshape(  1, 400, 600, 1 )        \n",
    "    \n",
    "    \n",
    "    result = modelTest.predict(image1)\n",
    "        \n",
    "    tClass = result.max()\n",
    "    \n",
    "    if(tClass == result[0][0]):\n",
    "        \n",
    "        print('Circle')\n",
    "\n",
    "    if(tClass == result[0][1]):\n",
    "        \n",
    "        print('Rectangle')\n",
    "        \n",
    "    if(tClass == result[0][2]):\n",
    "        \n",
    "        print('Triangle')    \n",
    "\n",
    "        \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "964064f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle\n",
      "[[9.9985993e-01 9.4094422e-24 9.8826563e-01]]\n"
     ]
    }
   ],
   "source": [
    "get_pred(\"images/img49999.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed672a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
